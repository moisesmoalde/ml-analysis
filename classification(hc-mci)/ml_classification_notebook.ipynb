{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
      },
      "source": [
        "# ML Classification of HC vs. MCI\n",
        "\n",
        "This notebook implements a machine learning pipeline for model optimization and evaluation, with the objective to classify participants between HC (healthy controls) and MCI (Mild Cognitive Impairment). Classification is based on GDS: MCI for GDS ≥ 3, healthy otherwise.\n",
        "\n",
        "Feature selection and ROC curve analysis is performed.\n",
        "\n",
        "\n"
      ],
      "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "1.  **Model Selection**: The pipeline evaluates four different models. Feel free to add/remove any models in the `estimators` list:\n",
        "\n",
        "    -   Stochastic Gradient Descent Classifier (Logistic Regression)\n",
        "    -   Support Vector Machine (Linear kernel)\n",
        "    -   Multi-layer Perceptron\n",
        "    -   Voting Classifier (ensemble of the above three)\n",
        "\n",
        "2.  **Cross-Validation**: Uses Leave-One-Group-Out cross-validation,\n",
        "    which is appropriate when you have multiple observations per\n",
        "    subject/group.\n",
        "\n",
        "3.  **Feature Selection**: Employs permutation importance for feature\n",
        "    selection, which is model-agnostic and works by measuring the\n",
        "    decrease in model performance when a feature is randomly shuffled.\n",
        "\n",
        "4.  **Evaluation Metrics**: Uses Area Under the ROC Curve (AUC) as the\n",
        "    primary metric for model evaluation.\n",
        "\n",
        "5.  **Visualization**: Creates two types of plots:\n",
        "\n",
        "    -   Feature importance and AUC vs. # of features, for each model\n",
        "    -   ROC curves comparing all models\n",
        "\n",
        "6.  **Output**: Saves results in the `results/` directory:\n",
        "\n",
        "    -   Best features for each model (CSV)\n",
        "    -   Feature importance plots (PNG)\n",
        "    -   Combined ROC curves (PNG)"
      ],
      "metadata": {
        "id": "Wn1C8okzU0S5"
      },
      "id": "Wn1C8okzU0S5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Setup and Imports"
      ],
      "metadata": {
        "id": "VKGPX1JnSjhU"
      },
      "id": "VKGPX1JnSjhU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard libraries\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sklearn classifiers\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
        "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, CategoricalNB, BernoulliNB\n",
        "from sklearn.ensemble import (VotingClassifier, RandomForestClassifier, AdaBoostClassifier,\n",
        "                            GradientBoostingClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Sklearn utilities\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import LeaveOneGroupOut, cross_val_predict\n",
        "from sklearn.metrics import mean_squared_error, r2_score, f1_score, roc_auc_score, RocCurveDisplay\n",
        "from sklearn.preprocessing import (StandardScaler, RobustScaler, MinMaxScaler,\n",
        "                                 PolynomialFeatures, MaxAbsScaler, Normalizer)"
      ],
      "metadata": {
        "id": "-Vw8-Nn0SfMS"
      },
      "id": "-Vw8-Nn0SfMS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n",
        "\n",
        "Define a function to visualize feature importances and their relationship with AUC scores:"
      ],
      "metadata": {
        "id": "fppdk5DPSbvf"
      },
      "id": "fppdk5DPSbvf"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importances(fis, auc_list, name):\n",
        "    \"\"\"\n",
        "    Create a dual-axis plot showing feature importances and AUC scores.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    fis : numpy.ndarray\n",
        "        Array of average feature importance scores\n",
        "    auc_list : list\n",
        "        List of AUC scores for different numbers of features\n",
        "    name : str\n",
        "        Model name for the output file\n",
        "\n",
        "    Output:\n",
        "    -------\n",
        "    Saves a plot showing feature importances (bars) and AUC scores (line)\n",
        "    with annotation for the optimal number of features\n",
        "    \"\"\"\n",
        "    # Create figure with two y-axes\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    # First y-axis: Feature Importances (bars)\n",
        "    color = 'tab:blue'\n",
        "    ax1.set_xlabel('Features')\n",
        "    ax1.set_ylabel('AVG Importances', color=color)\n",
        "    ax1.bar(range(1, len(auc_list) + 1), fis, color=color)\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Second y-axis: AUC scores (line)\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:red'\n",
        "    ax2.set_ylabel('AUC', color=color)\n",
        "    ax2.set_ylim(0, 1)\n",
        "    ax2.plot(range(1, len(auc_list) + 1), auc_list, color=color)\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Add annotation for optimal point\n",
        "    xmax = auc_list.index(max(auc_list)) + 1\n",
        "    ymax = max(auc_list)\n",
        "    text = f\"# Features = {xmax}, AUC = {ymax:.3f}\"\n",
        "\n",
        "    # Annotation styling\n",
        "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
        "    arrowprops = dict(arrowstyle=\"->\", connectionstyle=\"angle,angleA=0,angleB=60\")\n",
        "    kw = dict(xycoords='data', textcoords=\"axes fraction\",\n",
        "              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"top\")\n",
        "\n",
        "    # Add annotation\n",
        "    ax2.annotate(text, xy=(xmax, ymax), xytext=(0.94, 0.96), **kw)\n",
        "\n",
        "    # Save plot\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(f\"results/feature_importances_{name}.png\")\n",
        "    plt.clf()"
      ],
      "metadata": {
        "id": "eq3lRjBoSWjQ"
      },
      "id": "eq3lRjBoSWjQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition\n",
        "\n",
        "Define the machine learning models to evaluate. For file management purposes, we give each of them a short name:"
      ],
      "metadata": {
        "id": "R7lOZTd0STZV"
      },
      "id": "R7lOZTd0STZV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier configurations\n",
        "estimators = [\n",
        "    {\n",
        "        'model': SGDClassifier(loss='log_loss'),\n",
        "        'name': 'logit',\n",
        "    },\n",
        "    {\n",
        "        'model': SVC(kernel='linear', probability=True),\n",
        "        'name': 'svm',\n",
        "    },\n",
        "    {\n",
        "        'model': MLPClassifier(max_iter=100000),\n",
        "        'name': 'mlp',\n",
        "    },\n",
        "    {\n",
        "        'model': VotingClassifier(\n",
        "            estimators=[\n",
        "                ('sgdc', SGDClassifier(loss='log_loss')),\n",
        "                ('lsvc', SVC(kernel='linear', probability=True)),\n",
        "                ('mlpc', MLPClassifier(max_iter=100000))\n",
        "            ],\n",
        "            voting='soft'\n",
        "        ),\n",
        "        'name': 'vote',\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "9Sam2EC1SQdl"
      },
      "id": "9Sam2EC1SQdl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "Two datasets are loaded: `digimoca_results_totales.csv` and `datos_participantes_totales.csv`. These datasets are merged to create a unified dataset for analysis.\n",
        "\n",
        "We obtain the feature matrix (X) and target variable (y) for MCI detection. Classification is based on GDS: MCI for GDS ≥ 3, healthy otherwise.\n"
      ],
      "metadata": {
        "id": "_Whr7sxUSNBu"
      },
      "id": "_Whr7sxUSNBu"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "dataset = pd.read_csv(\"digimoca_results_totales.csv\")\n",
        "participants = pd.read_csv(\"datos_participantes_totales.csv\")\n",
        "\n",
        "# Merge datasets\n",
        "merged = pd.merge(participants, dataset, on='id')\n",
        "\n",
        "# Extract IDs for cross-validation grouping\n",
        "ids = merged['id']\n",
        "\n",
        "# Initialize Leave-One-Group-Out cross-validator\n",
        "logo = LeaveOneGroupOut()\n",
        "\n",
        "# Prepare feature matrix\n",
        "X = merged.drop(['GDS', 'id', 'gender', 'age', 'studies',\n",
        "                'lawton', 'MFE', 'T-MoCA', 'timestamp'], axis=1)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "X = pd.DataFrame(\n",
        "    scaler.fit_transform(X),\n",
        "    columns=scaler.get_feature_names_out()\n",
        ")\n",
        "\n",
        "# Prepare target variable (binary classification: GDS >= 3)\n",
        "y = merged['GDS'].transform(lambda gds: (0 if gds < 3 else 1)).values"
      ],
      "metadata": {
        "id": "juTv4aTJSJsy"
      },
      "id": "juTv4aTJSJsy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection and Model Evaluation\n",
        "\n",
        "Perform feature selection and evaluation for each model. We sort all the features based on their *permutation importance* and then we evaluate all subsets of features including the N most important (varying the N from 1 to all):\n"
      ],
      "metadata": {
        "id": "DuyNpolSSFyz"
      },
      "id": "DuyNpolSSFyz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through models\n",
        "for model in estimators:\n",
        "    # Fit model\n",
        "    model['model'].fit(X, y)\n",
        "\n",
        "    # Calculate feature importance using permutation importance\n",
        "    result = permutation_importance(\n",
        "        model['model'], X, y,\n",
        "        scoring='roc_auc',\n",
        "        n_repeats=100,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Convert to pandas Series for easier handling\n",
        "    avg_fi = pd.Series(result.importances_mean, index=X.columns.tolist())\n",
        "\n",
        "    # Evaluate different numbers of features\n",
        "    auc_list = []\n",
        "    for i in range(1, X.shape[1] + 1):\n",
        "        # Select top i features\n",
        "        X_best = X[avg_fi.nlargest(i).index]\n",
        "\n",
        "        # Get cross-validated predictions\n",
        "        y_pred = cross_val_predict(\n",
        "            model['model'], X_best, y,\n",
        "            cv=logo.split(merged, groups=ids),\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # Calculate and store AUC score\n",
        "        auc_list.append(roc_auc_score(y, y_pred))\n",
        "\n",
        "    # Print optimal number of features and corresponding AUC\n",
        "    print(f\"{model['name']}: {auc_list.index(max(auc_list)) + 1} features, \"\n",
        "          f\"AUC = {max(auc_list):.3f}\")\n",
        "\n",
        "    # Save best features\n",
        "    avg_fi.nlargest(auc_list.index(max(auc_list)) + 1).to_csv(\n",
        "        f\"results/best_features_{model['name']}.csv\"\n",
        "    )\n",
        "\n",
        "    # Plot feature importances\n",
        "    plot_feature_importances(\n",
        "        avg_fi.sort_values(ascending=False).values,\n",
        "        auc_list,\n",
        "        model['name']\n",
        "    )"
      ],
      "metadata": {
        "id": "qaoJFu7hSBpX"
      },
      "id": "qaoJFu7hSBpX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC Curve Generation\n",
        "\n",
        "Finally, generate ROC curves for all models using only the optimal set of features:"
      ],
      "metadata": {
        "id": "cAcUOhYIR2Kl"
      },
      "id": "cAcUOhYIR2Kl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Generate ROC curves for each model\n",
        "for model in estimators:\n",
        "    # Load best features for this model\n",
        "    best_features = pd.read_csv(\n",
        "        f\"results/best_features_{model['name']}.csv\",\n",
        "        index_col=0\n",
        "    )\n",
        "\n",
        "    # Select best features\n",
        "    X_best = X[best_features.index]\n",
        "\n",
        "    # Get probability predictions\n",
        "    y_pred = cross_val_predict(\n",
        "        model['model'], X_best, y,\n",
        "        cv=logo.split(merged, groups=ids),\n",
        "        n_jobs=-1,\n",
        "        method='predict_proba'\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve\n",
        "    RocCurveDisplay.from_predictions(\n",
        "        y,\n",
        "        y_pred[:, 1],\n",
        "        name=model['name'],\n",
        "        ax=ax,\n",
        "        alpha=0.8,\n",
        "        plot_chance_level=(model['name'] == 'vr')\n",
        "    )\n",
        "    ax = plt.gca()\n",
        "\n",
        "# Set labels\n",
        "ax.set(\n",
        "    xlabel=\"False Positive Rate\",\n",
        "    ylabel=\"True Positive Rate\"\n",
        ")\n",
        "\n",
        "# Save plot\n",
        "plt.savefig(f\"results/roc_{'_'.join([model['name'] for model in estimators])}.png\")"
      ],
      "metadata": {
        "id": "51gpn_0URuTQ"
      },
      "id": "51gpn_0URuTQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VKGPX1JnSjhU",
        "fppdk5DPSbvf",
        "R7lOZTd0STZV",
        "_Whr7sxUSNBu",
        "DuyNpolSSFyz",
        "cAcUOhYIR2Kl"
      ]
    }
  }
}