{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4b05df9b",
      "metadata": {
        "id": "4b05df9b"
      },
      "source": [
        "\n",
        "# Machine Learning Regression Analysis\n",
        "This notebook evaluates various regression models to predict a target variable (`T-MoCA`) based on feature importance analysis. It includes:\n",
        "- Data preprocessing\n",
        "- Feature selection based on permutation importance\n",
        "- Cross-validation to evaluate performance (R-squared and RMSE)\n",
        "- Visualization of results for insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7184cb2a",
      "metadata": {
        "id": "7184cb2a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, Ridge, BayesianRidge\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import LeaveOneGroupOut, cross_val_predict\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10f30019",
      "metadata": {
        "id": "10f30019"
      },
      "source": [
        "\n",
        "## Load and Merge Data\n",
        "Two datasets are loaded: `digimoca_results_totales.csv` and `datos_participantes_totales.csv`. These datasets are merged to create a unified dataset for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62403a1c",
      "metadata": {
        "id": "62403a1c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load datasets\n",
        "dataset = pd.read_csv(\"digimoca_results_totales.csv\")\n",
        "participants = pd.read_csv(\"datos_participantes_totales.csv\")\n",
        "\n",
        "# Merge datasets\n",
        "merged = pd.merge(participants, dataset, on='id')\n",
        "\n",
        "# Display the first few rows of the merged dataset\n",
        "merged.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba7b4a3a",
      "metadata": {
        "id": "ba7b4a3a"
      },
      "source": [
        "\n",
        "## Data Preprocessing\n",
        "- **Feature Selection**: Drop irrelevant or redundant features.\n",
        "- **Feature Scaling**: Apply robust scaling to normalize the feature space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86f10c79",
      "metadata": {
        "id": "86f10c79"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define features and target variable\n",
        "ids = merged['id']\n",
        "X = merged.drop(['GDS', 'id', 'gender', 'age', 'studies', 'lawton', 'MFE', 'T-MoCA', 'timestamp'], axis=1)\n",
        "y = merged[['T-MoCA']].values.ravel()\n",
        "\n",
        "# Apply robust scaling\n",
        "scaler = RobustScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Display scaled features\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64306102",
      "metadata": {
        "id": "64306102"
      },
      "source": [
        "\n",
        "## Model Selection and Evaluation\n",
        "Some of the linear models are evaluated, but feel free to include any other in the estimators list.\n",
        "For it, create an instance of the Scikit-learn model you want to use, and give it a name to identify it.\n",
        "Evaluation is performed using:\n",
        "- Permutation importance to determine feature relevance.\n",
        "- Leave-One-Group-Out (LOGO) Cross-Validation to assess model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2775db62",
      "metadata": {
        "id": "2775db62"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define models\n",
        "estimators = [\n",
        "    {'model': LinearRegression(), 'name': 'lr'},\n",
        "    {'model': Ridge(), 'name': 'ri'},\n",
        "    {'model': BayesianRidge(), 'name': 'bar'},\n",
        "    {'model': PLSRegression(n_components=1), 'name': 'plsr'}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd9b6382",
      "metadata": {
        "id": "fd9b6382"
      },
      "source": [
        "\n",
        "## Evaluate Models and Feature Importance\n",
        "For each model:\n",
        "1. Fit the model.\n",
        "2. Compute permutation importance to rank features.\n",
        "3. Calculate R-squared for varying numbers of top features.\n",
        "4. Plot feature importance and R-squared.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98a94fce",
      "metadata": {
        "id": "98a94fce"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to plot feature importances and R2 scores\n",
        "def plot_feature_importances(fis, r2_list, name):\n",
        "    fig, ax1 = plt.subplots()\n",
        "    color = 'tab:blue'\n",
        "    ax1.set_xlabel('Features')\n",
        "    ax1.set_ylabel('AVG Importances', color=color)\n",
        "    ax1.bar(range(1, len(r2_list) + 1), fis, color=color)\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:red'\n",
        "    ax2.set_ylabel('R2 score', color=color)\n",
        "    ax2.plot(range(1, len(r2_list) + 1), r2_list, color=color)\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate models\n",
        "for model in estimators:\n",
        "    model['model'].fit(X, y)\n",
        "    result = permutation_importance(model['model'], X, y, scoring='r2', n_repeats=100, n_jobs=-1)\n",
        "    avg_fi = pd.Series(result.importances_mean, index=X.columns.tolist())\n",
        "\n",
        "    r2_list = []\n",
        "    for i in range(1, X.shape[1] + 1):\n",
        "        X_best = X[avg_fi.nlargest(i).index]\n",
        "        y_pred = cross_val_predict(model['model'], X_best, y, cv=LeaveOneGroupOut().split(merged, groups=ids), n_jobs=-1)\n",
        "        r2_list.append(r2_score(y, y_pred))\n",
        "\n",
        "    # Display R2 scores\n",
        "    print(f\"{model['name']}: Optimal features: {r2_list.index(max(r2_list)) + 1}, Max R2: {max(r2_list)}\")\n",
        "    plot_feature_importances(avg_fi.sort_values(ascending=False).values, r2_list, model['name'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7f27eb3",
      "metadata": {
        "id": "c7f27eb3"
      },
      "source": [
        "\n",
        "## Scatter Plot of Predictions\n",
        "Generate scatter plots for predicted vs true values for all models.\n",
        "\n",
        "**IMPORTANT: make sure to include 4 models at a time in the estimators list for this section** (or modify the `scatter_plot()` function in order to adapt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21244c7",
      "metadata": {
        "id": "b21244c7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to plot scatter plots\n",
        "def scatter_plot(y, y_pred_list, estimators):\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(9, 7))\n",
        "    axs = np.ravel(axs)\n",
        "    for ax, est, y_pred in zip(axs, estimators, y_pred_list):\n",
        "        name = type(est['model']).__name__\n",
        "        r2 = r2_score(y, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "        ax.plot([y.min(), y.max()], [y.min(), y.max()], \"--r\", linewidth=2)\n",
        "        ax.scatter(y, y_pred, alpha=0.2)\n",
        "        ax.set_title(f\"{name} (R2: {r2:.2f}, RMSE: {rmse:.2f})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate predictions and scatter plots\n",
        "y_pred_list = []\n",
        "for model in estimators:\n",
        "    best_features = pd.DataFrame(avg_fi.nlargest(r2_list.index(max(r2_list)) + 1).index)\n",
        "    X_best = X[best_features[0]]\n",
        "    y_pred = cross_val_predict(model['model'], X_best, y, cv=LeaveOneGroupOut().split(merged, groups=ids), n_jobs=-1)\n",
        "    y_pred_list.append(y_pred)\n",
        "\n",
        "scatter_plot(y, y_pred_list, estimators)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}